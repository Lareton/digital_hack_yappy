{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "695165ce-0b5c-41bd-aa9b-51b9c49bc1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ced71e5e-c8cf-4e17-b252-7135c2f220a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install av\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b632f34d-9c6e-4df3-97ad-7a87977871dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34bf3d09-36f3-429c-baec-9fb26f3745b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Pillow==9.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "553478f1-1886-466d-a52d-5ec4ffafd5ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip3 install --upgrade jupyter-console\n",
    "# !pip3 install --upgrade jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11229877-ee2c-4b74-9361-775277e4f44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/MKLab-ITI/visil.git visil_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8c7e9e2-aebd-46a6-9e6a-6417f2c2ea08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy>=1.9 in /usr/local/lib/python3.10/dist-packages (from -r visil_pytorch/requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: tqdm>=4.2 in /usr/local/lib/python3.10/dist-packages (from -r visil_pytorch/requirements.txt (line 2)) (4.66.5)\n",
      "Requirement already satisfied: opencv-python>=3.1 in /home/user1/.local/lib/python3.10/site-packages (from -r visil_pytorch/requirements.txt (line 3)) (4.10.0.84)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r visil_pytorch/requirements.txt (line 4)) (1.5.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r visil_pytorch/requirements.txt (line 4)) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r visil_pytorch/requirements.txt (line 4)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r visil_pytorch/requirements.txt (line 4)) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r visil_pytorch/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82666d61-4b06-4009-a3d4-94fcbfed9fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile,os.path\n",
    "def unzip(source_filename, dest_dir):\n",
    "    with zipfile.ZipFile(source_filename) as zf:\n",
    "        for member in zf.infolist():\n",
    "            # Path traversal defense copied from\n",
    "            # http://hg.python.org/cpython/file/tip/Lib/http/server.py#l789\n",
    "            words = member.filename.split('/')\n",
    "            path = dest_dir\n",
    "            for word in words[:-1]:\n",
    "                while True:\n",
    "                    drive, word = os.path.splitdrive(word)\n",
    "                    head, word = os.path.split(word)\n",
    "                    if not drive:\n",
    "                        break\n",
    "                if word in (os.curdir, os.pardir, ''):\n",
    "                    continue\n",
    "                path = os.path.join(path, word)\n",
    "            zf.extract(member, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "167bc1c8-3f38-4808-be12-425547ec7ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib.request\n",
    "\n",
    "# # URL of the file\n",
    "# url = \"http://ndd.iti.gr/visil/ckpt.zip\"\n",
    "\n",
    "# # Download the file and save it locally\n",
    "# urllib.request.urlretrieve(url, \"ckpt.zip\")\n",
    "\n",
    "# print(\"File downloaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6afe93c2-ebc2-4c0f-9cd4-1c6d3eee98a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://ndd.iti.gr/visil/ckpt.zip\n",
    "# !unzip ckpt.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "480b409c-7c14-4397-9e95-44589207e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip(\"data_finetune.zip\", \"data_finetune\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2c40fe-5e11-4252-8f75-9b04e0b95dc5",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ff00448-18ed-4013-9819-c63f1646ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import skvideo.io\n",
    "import torch, torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "# import timm\n",
    "import time\n",
    "import gc\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "# import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9e59d78-5577-464b-b561-3ef369a0c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_cache():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d72d198-c905-4426-8cbf-109a333d62c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fa30865-02b1-463b-8860-e7fadded3506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    \"\"\"\n",
    "    Обеспечивает воспроизводимость экспериментов\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ccb6182-4896-41b7-9a84-e1aed1455b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>duplicate_for</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3dd424ce-f0e5-4727-88a3-8f318b612afd</td>\n",
       "      <td>1e9efc51-a74c-4f32-b03e-71905f8d6dd1</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d444f2d0-a7cd-4c9b-bc56-8d5ef88ec015</td>\n",
       "      <td>1e9efc51-a74c-4f32-b03e-71905f8d6dd1</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49292bf9-dc53-44d5-9980-a658ab3a3921</td>\n",
       "      <td>1e9efc51-a74c-4f32-b03e-71905f8d6dd1</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6a816304-7c1b-4c16-81c6-09f46bb0ad63</td>\n",
       "      <td>1e9efc51-a74c-4f32-b03e-71905f8d6dd1</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1f4df893-663e-4ca3-a6ca-46819aebd8a3</td>\n",
       "      <td>3dd424ce-f0e5-4727-88a3-8f318b612afd</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>2f33171f-a356-4dfc-8fc5-b0c492f8d091</td>\n",
       "      <td>15208cba-2aee-41e1-8073-18bb68dad838</td>\n",
       "      <td>False</td>\n",
       "      <td>false_positives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>33afb61d-c38c-4e3a-95e5-78b06c38cf0e</td>\n",
       "      <td>0670afa5-d74e-4ae9-82dd-8dc7aee1ffc7</td>\n",
       "      <td>False</td>\n",
       "      <td>false_positives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>367b94a1-4757-4cf3-a726-ca0088f67dd8</td>\n",
       "      <td>3ba31a54-e0a0-48ff-82e8-af0db8a5e873</td>\n",
       "      <td>False</td>\n",
       "      <td>false_positives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>1eb88ab3-ebbd-41e8-a5b3-7fb19914a677</td>\n",
       "      <td>2c5a5717-72b0-4374-be04-b9d823425101</td>\n",
       "      <td>False</td>\n",
       "      <td>false_positives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>2efeecac-5fb3-42ce-b7f3-a06f975cc2b3</td>\n",
       "      <td>56e61c38-710c-4825-9678-444497b0378a</td>\n",
       "      <td>False</td>\n",
       "      <td>false_positives</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     uuid  \\\n",
       "0    3dd424ce-f0e5-4727-88a3-8f318b612afd   \n",
       "1    d444f2d0-a7cd-4c9b-bc56-8d5ef88ec015   \n",
       "2    49292bf9-dc53-44d5-9980-a658ab3a3921   \n",
       "3    6a816304-7c1b-4c16-81c6-09f46bb0ad63   \n",
       "4    1f4df893-663e-4ca3-a6ca-46819aebd8a3   \n",
       "..                                    ...   \n",
       "755  2f33171f-a356-4dfc-8fc5-b0c492f8d091   \n",
       "756  33afb61d-c38c-4e3a-95e5-78b06c38cf0e   \n",
       "757  367b94a1-4757-4cf3-a726-ca0088f67dd8   \n",
       "758  1eb88ab3-ebbd-41e8-a5b3-7fb19914a677   \n",
       "759  2efeecac-5fb3-42ce-b7f3-a06f975cc2b3   \n",
       "\n",
       "                            duplicate_for  is_duplicate             type  \n",
       "0    1e9efc51-a74c-4f32-b03e-71905f8d6dd1         False             hard  \n",
       "1    1e9efc51-a74c-4f32-b03e-71905f8d6dd1         False             hard  \n",
       "2    1e9efc51-a74c-4f32-b03e-71905f8d6dd1         False             hard  \n",
       "3    1e9efc51-a74c-4f32-b03e-71905f8d6dd1         False             hard  \n",
       "4    3dd424ce-f0e5-4727-88a3-8f318b612afd         False             hard  \n",
       "..                                    ...           ...              ...  \n",
       "755  15208cba-2aee-41e1-8073-18bb68dad838         False  false_positives  \n",
       "756  0670afa5-d74e-4ae9-82dd-8dc7aee1ffc7         False  false_positives  \n",
       "757  3ba31a54-e0a0-48ff-82e8-af0db8a5e873         False  false_positives  \n",
       "758  2c5a5717-72b0-4374-be04-b9d823425101         False  false_positives  \n",
       "759  56e61c38-710c-4825-9678-444497b0378a         False  false_positives  \n",
       "\n",
       "[760 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv(\"y_finetune.csv\")\n",
    "# y = y.sort_values('created')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2cadd77-406e-4f12-9465-2050d4e4c858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_duplicate\n",
       "False    0.543421\n",
       "True     0.456579\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['is_duplicate'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d3f192-77ca-4add-bf9f-1b7229260a5a",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "303dbacb-ade7-43b3-a46d-1dc5438c839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, videos1, videos2, labels):\n",
    "        self.videos1 = videos1\n",
    "        self.videos2 = videos2\n",
    "        self.labels = [int(l) for l in labels]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.videos1)\n",
    "\n",
    "    def load_frames(self, video):\n",
    "        return torch.from_numpy(load_video(os.path.join(\"data_finetune/data_finetune/data_finetune\", video+'.mp4')))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        videos = {'video1' : self.videos1[idx], 'video2': self.videos2[idx]}\n",
    "        \n",
    "        frames = {}\n",
    "        frames['video1'] = self.load_frames(videos['video1'])\n",
    "        frames['video2'] = self.load_frames(videos['video2'])\n",
    "\n",
    "\n",
    "        return videos, frames, self.labels[idx]\n",
    "\n",
    "dataset_train = VideoDataset(y['uuid'].values, y['duplicate_for'].values, y['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7acb9575-b145-4dcd-bef8-171d0143d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCollator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        # self.cfg = cfg\n",
    "        # self.processor = processor\n",
    "        # self.max_length = max_length\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # print(batch)\n",
    "        videos_batch = {'video1' : [], 'video2': []}\n",
    "        frames_batch = {'video1' : [], 'video2': []}\n",
    "        lengths = {'video1' : [], 'video2': []}\n",
    "        labels = []\n",
    "\n",
    "        for videos, frames, label in batch:\n",
    "            labels.append(label)\n",
    "            for video_type in ['video1', 'video2']:\n",
    "                \n",
    "                videos_batch[video_type].append(videos[video_type])\n",
    "\n",
    "                video_frames = frames[video_type]\n",
    "\n",
    "                lengths[video_type].append(len(video_frames))\n",
    "                frames_batch[video_type].append(video_frames)\n",
    "            \n",
    "        for video_type in ['video1', 'video2']:\n",
    "            frames_batch[video_type] = torch.concatenate(frames_batch[video_type], dim=0)\n",
    "        \n",
    "        return videos_batch, frames_batch, lengths, torch.tensor(labels)\n",
    "\n",
    "data_collator = DataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3c319dd-bcc6-417c-a8b4-8aa1678d0775",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(dataset_train, batch_size=2, collate_fn=data_collator, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84884825-0e65-42b3-8602-8efcfbf6606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visil_pytorch.utils import load_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b819d24f-df38-4cca-bd57-4458942748d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in dataloader_train:\n",
    "    break\n",
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c6fc082-1ecc-4e2a-aa72-ab4f6568c347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('visil_pytorch/')\n",
    "\n",
    "from visil_pytorch.utils import load_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "534e52a5-313f-4218-a9e1-4c45fae521fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for videos, frames, lengths, labels in dataloader_train:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c54d6de9-1044-4854-8cfa-c0fee68407a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video1': ['cbacb5ab-5b69-400e-8572-28d26d0b56e8',\n",
       "  '3c21a653-5701-4aa0-99e6-2787a08f50fe'],\n",
       " 'video2': ['1659eef1-e919-4077-82da-cca40d277bf1',\n",
       "  '48776192-a1d2-4e88-b8a4-e5f65edaa06b']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "021cd18b-3fa9-4fbf-bc26-684e308c64ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31, 224, 224, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames['video1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0aa7405f-3c1b-4a0f-8987-de835d2cb45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 23]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths['video1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35da0600-345a-4113-b655-27fa72c26455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd00e67f-d932-45de-9207-b79b8aa04142",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02e59163-2271-4631-9859-8c32ca5bd640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('visil_pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30d1f538-9290-426a-8ba7-97e127e987fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from model.visil import *\n",
    "\n",
    "\n",
    "device = torch.device('cuda')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6830d6af-d199-4fc6-a92e-99ceeebba464",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f2f9c1a-96bc-4a47-bd05-923cdeea6474",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CosineContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5):\n",
    "        super(CosineContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, embedding1, embedding2, label):\n",
    "        # Cosine similarity ranges from -1 to 1\n",
    "        cos_sim = F.cosine_similarity(embedding1, embedding2)\n",
    "        loss_pos = (label * (1 - cos_sim)).mean()  # For positive pairs (similar)\n",
    "        # loss_neg = ((1 - label) * torch.clamp(cos_sim - self.margin, min=0.0)).mean()  # For negative pairs (dissimilar)\n",
    "        loss_neg = ((1 - label) * (cos_sim + 1)).mean()  # For negative pairs (dissimilar)\n",
    "        return loss_pos + loss_neg\n",
    "\n",
    "criterion = CosineContrastiveLoss(margin=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bc49196-3899-40ac-8240-8a2cd16b8678",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViSiL(nn.Module):\n",
    "    \n",
    "    def __init__(self, network='resnet50', pretrained=False, dims=3840,\n",
    "                 whiteninig=True, attention=True, video_comperator=True, symmetric=False):\n",
    "        super(ViSiL, self).__init__()\n",
    "        \n",
    "        if pretrained and not symmetric:\n",
    "            self.cnn = Feature_Extractor('resnet50', True, 3840)\n",
    "            self.visil_head = ViSiLHead(3840, True, True, False)\n",
    "            self.visil_head.load_state_dict(\n",
    "                torch.hub.load_state_dict_from_url(\n",
    "                    'http://ndd.iti.gr/visil/visil.pth'))\n",
    "        elif pretrained and symmetric:\n",
    "            self.cnn = Feature_Extractor('resnet50', True, 512)\n",
    "            self.visil_head = ViSiLHead(512, True, True, True)\n",
    "            self.visil_head.load_state_dict(\n",
    "                torch.hub.load_state_dict_from_url(\n",
    "                    'http://ndd.iti.gr/visil/visil_symmetric.pth'))\n",
    "        else:\n",
    "            self.cnn = Feature_Extractor(network, whiteninig, dims)\n",
    "            self.visil_head = ViSiLHead(dims, attention, video_comperator, symmetric)\n",
    "    \n",
    "    def calculate_video_similarity(self, query, target):\n",
    "        return self.visil_head(query, target)\n",
    "\n",
    "    def calculate_f2f_matrix(self, query, target):\n",
    "        return self.visil_head.frame_to_frame_similarity(query, target)\n",
    "\n",
    "    def calculate_visil_output(self, query, target):\n",
    "        sim = self.visil_head.frame_to_frame_similarity(query, target)\n",
    "        return self.visil_head.visil_output(sim)\n",
    "        \n",
    "    def forward(self, video_tensors, lengths):\n",
    "        # print(1, time.time())\n",
    "        # print(video_tensor.shape)\n",
    "        cnn_features = self.cnn(video_tensors)\n",
    "        features = []\n",
    "        # print(features.shape)\n",
    "        # print(2, time.time())\n",
    "        sum_length = 0\n",
    "        for length in lengths:\n",
    "            feature  = cnn_features[sum_length:sum_length+length]\n",
    "            # print(feature.shape, feature[0])\n",
    "            sum_length += length\n",
    "\n",
    "            feature = self.visil_head.prepare_tensor(feature)\n",
    "            features.append(feature.mean(dim=0))\n",
    "            \n",
    "        features = torch.stack(features)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1c1f4fe-daa2-436a-83e0-c60c34013493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user1/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/user1/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Initialize pretrained ViSiL model\n",
    "model = ViSiL(pretrained=True).to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11a0e093-052c-47f7-a50d-3bd10caccb2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video1': ['cbacb5ab-5b69-400e-8572-28d26d0b56e8',\n",
       "  '3c21a653-5701-4aa0-99e6-2787a08f50fe'],\n",
       " 'video2': ['1659eef1-e919-4077-82da-cca40d277bf1',\n",
       "  '48776192-a1d2-4e88-b8a4-e5f65edaa06b']}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8724b17d-e597-41e3-97d9-36fe615fde0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecea9c23-18fe-4501-8880-3a934d54db0d",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69257b49-2e9b-4c39-9604-7a7c01d819a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27d27825-6f59-461d-af31-2df0b309fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del frames, video1_embeds, video2_embeds\n",
    "empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50425af3-4266-40fd-99d7-09c28db186f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_131600/1538717384.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"model_0.pt\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-5)\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "num_epochs=2\n",
    "device='cuda'\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"model_0.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1066fd-b080-44ea-a5fa-f378bb47e154",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09e99a9a2e145f6a540417855ce8316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC -1\n",
      "Loss 0.0\n",
      "--------------------------------------------------\n",
      "AUC 0.9173553719008265\n",
      "Loss 0.964179662140933\n",
      "--------------------------------------------------\n",
      "AUC 0.9568181818181818\n",
      "Loss 1.0244512274151756\n",
      "--------------------------------------------------\n",
      "AUC 0.9241452991452992\n",
      "Loss 1.0839240243357997\n",
      "--------------------------------------------------\n",
      "AUC 0.9239130434782609\n",
      "Loss 1.1475701026800202\n",
      "--------------------------------------------------\n",
      "AUC 0.8912037037037036\n",
      "Loss 1.1119052089896857\n",
      "--------------------------------------------------\n",
      "AUC 0.8822252374491181\n",
      "Loss 1.151971215107402\n",
      "--------------------------------------------------\n",
      "AUC 0.8787212787212788\n",
      "Loss 1.1311018739787626\n",
      "--------------------------------------------------\n",
      "AUC 0.875\n",
      "Loss 1.1634588120160279\n",
      "--------------------------------------------------\n",
      "AUC 0.8690115221346271\n",
      "Loss 1.167564984533813\n",
      "--------------------------------------------------\n",
      "AUC 0.8637481554353172\n",
      "Loss 1.1457638572348225\n",
      "--------------------------------------------------\n",
      "AUC 0.8630637952052012\n",
      "Loss 1.1475331195302911\n",
      "--------------------------------------------------\n",
      "AUC 0.8653885655597399\n",
      "Loss 1.1560296551747755\n",
      "--------------------------------------------------\n",
      "AUC 0.866116862607475\n",
      "Loss 1.160805539547942\n",
      "--------------------------------------------------\n",
      "AUC 0.8720141700404858\n",
      "Loss 1.1661385335820786\n",
      "--------------------------------------------------\n",
      "AUC 0.8792564204220078\n",
      "Loss 1.1580364775183976\n",
      "--------------------------------------------------\n",
      "AUC 0.8847079838459149\n",
      "Loss 1.1622455584706728\n",
      "--------------------------------------------------\n",
      "AUC 0.8884493670886076\n",
      "Loss 1.150544644970643\n",
      "--------------------------------------------------\n",
      "AUC 0.8842622447412867\n",
      "Loss 1.1493678680770305\n",
      "--------------------------------------------------\n",
      "AUC 0.8879586648983201\n",
      "Loss 1.1538742768202777\n",
      "--------------------------------------------------\n",
      "AUC 0.8855203732814333\n",
      "Loss 1.156100317909943\n",
      "--------------------------------------------------\n",
      "AUC 0.8847599637681159\n",
      "Loss 1.1541597973113942\n",
      "--------------------------------------------------\n",
      "AUC 0.8842109620798145\n",
      "Loss 1.1593049713389367\n",
      "--------------------------------------------------\n",
      "AUC 0.891131102953763\n",
      "Loss 1.1636508553575127\n",
      "--------------------------------------------------\n",
      "AUC 0.8916470690706384\n",
      "Loss 1.1563064584593554\n",
      "--------------------------------------------------\n",
      "AUC 0.8933089027114776\n",
      "Loss 1.1483510695843107\n",
      "--------------------------------------------------\n",
      "AUC 0.8950802615933413\n",
      "Loss 1.1454426739864423\n",
      "--------------------------------------------------\n",
      "AUC 0.8969052357098746\n",
      "Loss 1.1273296198281855\n",
      "--------------------------------------------------\n",
      "AUC 0.9004499437570304\n",
      "Loss 1.1253572305750592\n",
      "--------------------------------------------------\n",
      "AUC 0.9003182473747572\n",
      "Loss 1.1250281503929715\n",
      "--------------------------------------------------\n",
      "AUC 0.9036752849596887\n",
      "Loss 1.1164655823050147\n",
      "--------------------------------------------------\n",
      "AUC 0.9035339660339661\n",
      "Loss 1.1101590672873225\n",
      "--------------------------------------------------\n",
      "AUC 0.9049284423386901\n",
      "Loss 1.1067763080478086\n",
      "--------------------------------------------------\n",
      "AUC 0.9068380623346074\n",
      "Loss 1.1063149385942073\n",
      "--------------------------------------------------\n",
      "AUC 0.9046739507457509\n",
      "Loss 1.1123680112298981\n",
      "--------------------------------------------------\n",
      "AUC 0.9027786858450474\n",
      "Loss 1.107843024098975\n",
      "--------------------------------------------------\n",
      "AUC 0.9001546072974644\n",
      "Loss 1.1140897523333162\n",
      "--------------------------------------------------\n",
      "AUC 0.9020352781546812\n",
      "Loss 1.119786600378967\n",
      "--------------------------------------------------\n",
      "Epoch [2/2], Loss: 1.1159\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab490fde97e946f18989d22f58ac385d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC -1\n",
      "Loss 0.0\n",
      "--------------------------------------------------\n",
      "AUC 0.7946428571428572\n",
      "Loss 1.182900147004561\n",
      "--------------------------------------------------\n",
      "AUC 0.8795454545454545\n",
      "Loss 1.0249127206348239\n",
      "--------------------------------------------------\n",
      "AUC 0.9072916666666666\n",
      "Loss 0.9541967559245325\n",
      "--------------------------------------------------\n",
      "AUC 0.9083878643664485\n",
      "Loss 0.9549648878051014\n",
      "--------------------------------------------------\n",
      "AUC 0.8947775628626693\n",
      "Loss 0.9296212354127098\n",
      "--------------------------------------------------\n",
      "AUC 0.873144399460189\n",
      "Loss 0.9676878305732227\n",
      "--------------------------------------------------\n",
      "AUC 0.8945374800637957\n",
      "Loss 0.9674933968295514\n",
      "--------------------------------------------------\n",
      "AUC 0.8832183908045977\n",
      "Loss 0.9713745279076659\n",
      "--------------------------------------------------\n",
      "AUC 0.8915065845112964\n",
      "Loss 1.002977505817518\n",
      "--------------------------------------------------\n",
      "AUC 0.8794117647058823\n",
      "Loss 1.0389385090606047\n",
      "--------------------------------------------------\n",
      "AUC 0.8814123376623376\n",
      "Loss 1.0366205763709437\n",
      "--------------------------------------------------\n",
      "AUC 0.8803418803418803\n",
      "Loss 1.0659014521058925\n",
      "--------------------------------------------------\n",
      "AUC 0.8809232383283792\n",
      "Loss 1.0553047336239851\n",
      "--------------------------------------------------\n",
      "AUC 0.8851106639839034\n",
      "Loss 1.0503104576405058\n",
      "--------------------------------------------------\n",
      "AUC 0.8835637480798771\n",
      "Loss 1.053214642188407\n",
      "--------------------------------------------------\n",
      "AUC 0.8858443964186478\n",
      "Loss 1.0491274915496756\n",
      "--------------------------------------------------\n",
      "AUC 0.8914389301227895\n",
      "Loss 1.0316317771610461\n",
      "--------------------------------------------------\n",
      "AUC 0.8909762952101662\n",
      "Loss 1.0361173574437095\n",
      "--------------------------------------------------\n",
      "AUC 0.8915953478165459\n",
      "Loss 1.0308896677656323\n",
      "--------------------------------------------------\n",
      "AUC 0.8908482142857143\n",
      "Loss 1.0302432028215323\n",
      "--------------------------------------------------\n",
      "AUC 0.897597977243995\n",
      "Loss 1.026954236047528\n",
      "--------------------------------------------------\n",
      "AUC 0.8879567986478967\n",
      "Loss 1.034902344057463\n",
      "--------------------------------------------------\n",
      "AUC 0.889621646065722\n",
      "Loss 1.0418964316060533\n",
      "--------------------------------------------------\n",
      "AUC 0.8887907137907138\n",
      "Loss 1.051936067486205\n",
      "--------------------------------------------------\n",
      "AUC 0.8821440568165458\n",
      "Loss 1.0537354370274867\n",
      "--------------------------------------------------\n",
      "AUC 0.8822489864413324\n",
      "Loss 1.0694291105215576\n",
      "--------------------------------------------------\n",
      "AUC 0.883237979975795\n",
      "Loss 1.0624886016564177\n",
      "--------------------------------------------------\n",
      "AUC 0.8797598518234655\n",
      "Loss 1.0670125472800163\n",
      "--------------------------------------------------\n",
      "AUC 0.8790072019522648\n",
      "Loss 1.0622477576495035\n",
      "--------------------------------------------------\n",
      "AUC 0.880804367201426\n",
      "Loss 1.0649416551637492\n",
      "--------------------------------------------------\n",
      "AUC 0.8775678067572492\n",
      "Loss 1.0658634972917305\n",
      "--------------------------------------------------\n",
      "AUC 0.8744727386345884\n",
      "Loss 1.0667603138451265\n",
      "--------------------------------------------------\n",
      "AUC 0.8718263981281829\n",
      "Loss 1.0698477883353334\n",
      "--------------------------------------------------\n",
      "AUC 0.8656324272935483\n",
      "Loss 1.0743138839072846\n",
      "--------------------------------------------------\n",
      "AUC 0.862762701489492\n",
      "Loss 1.079934244736647\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    # correct, total = 0, 0\n",
    "    preds = []\n",
    "    targets = []\n",
    "    for i, (videos, frames, lengths, labels) in tqdm(enumerate(dataloader_train), total=len(dataloader_train)):\n",
    "        frames = {k:v.to(device) for k, v in frames.items()}\n",
    "\n",
    "        labels[labels == 0] = -1\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 1/0\n",
    "        \n",
    "        # Forward pass\n",
    "        video1_embeds = model(frames['video1'], lengths['video1'])\n",
    "        video1_embeds = video1_embeds.reshape(video1_embeds.shape[0], -1)\n",
    "        video2_embeds = model(frames['video2'], lengths['video2'])\n",
    "        video2_embeds = video2_embeds.reshape(video2_embeds.shape[0], -1)\n",
    "\n",
    "        loss = criterion(video1_embeds, video2_embeds, labels.to(device))\n",
    "\n",
    "        for (p, t) in zip(F.cosine_similarity(video1_embeds, video2_embeds).cpu().tolist(), labels):\n",
    "            preds.append(p)\n",
    "            targets.append(t if t > 0 else 0)\n",
    "            # if p == t or (p == 0 and t == -1):\n",
    "            #     correct += 1\n",
    "            # total += 1\n",
    "\n",
    "        # 1/0\n",
    "        if i % 10 == 0:\n",
    "            # print('ACC', correct/total)\n",
    "            try:\n",
    "                print(\"AUC\", roc_auc_score(targets, preds))\n",
    "            except:\n",
    "                print(\"AUC\", -1)\n",
    "            print('Loss', running_loss /( i + 1))\n",
    "            print('-'*50)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        del frames, video1_embeds, video2_embeds\n",
    "        empty_cache()\n",
    "\n",
    "        # print(loss.item())\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader_train)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "    torch.save(model.state_dict(), f'model_{epoch}.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
